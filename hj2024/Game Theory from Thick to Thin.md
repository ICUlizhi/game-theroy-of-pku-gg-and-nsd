- åœ¨å‰äººåŸºç¡€ä¸Šä¼˜åŒ–çš„ç¬”è®°
  - æ„Ÿè§‰è¯æ˜ä¸ä¼šè€ƒ, ç½—åˆ—ç»“è®ºæ—¶æ²¡æœ‰å†™è¯æ˜
  - æ•´ç†äº†å›ºå®šé¢˜å‹å’Œåº”å¯¹æ–¹æ³•
    - ğŸ”¥è¡¨ç¤ºéš¾åº¦, 3ä¸ªğŸ”¥æœ€éš¾
- åšå¼ˆè®ºé—®é¢˜çš„æ±‚è§£å¾€å¾€è•´å«åœ¨æ¦‚å¿µä¹‹ä¸­, tricks æ˜¯æ‘†åœ¨æ˜é¢ä¸Šçš„.
- è®¤ä¸ºæ¯”è¾ƒæ ¸å¿ƒçš„æ€æƒ³ :
  - br çš„äº¤ç‚¹æ˜¯ ne
  - ä»£å…¥ä¸ºåšå¼ˆç©å®¶, æŸ¥è¯¢æ— å¯è·åˆ©åç¦»
  - ä¸å¯ç½®ä¿¡çš„å¨èƒ
  - æœ‰é™åšå¼ˆä¸‹çš„ä¸€äº›ç»“è®ºå¾€å¾€åœ¨è¿ç»­/æ— é™åšå¼ˆå¤±æ•ˆ, å­˜åœ¨åä¾‹

æ¬¢è¿è¡¥å……

## Handout 2

1. **æ­£åˆ™åšå¼ˆ (normal form game)**
   - **definition** : ä¸€ä¸ªä¸‰å…ƒç»„(triple) : $(N=[n],\{S_i\}_n,\{v_i\}_n)$
   - **ç­–ç•¥ç»„åˆ (strategy profile)** : $s\in S=S_1\times S_2\times \cdots \times S_n$
     - æœ‰é™åšå¼ˆ $\Leftrightarrow$ ç­–ç•¥ç»„åˆæ˜¯æœ‰é™çš„ $\Leftrightarrow$ æ¯ä¸ªäººçš„ç­–ç•¥æœ‰é™
   - **æ­£åˆ™è¡¨ç¤ºä¹Ÿèƒ½è¡¨ç¤ºè¿ç»­æƒ…å†µ** : ä¾‹å¦‚ Cournot æ¨¡å‹

> - **æ‹å–**
>   - ä¸€ä»·æ‹å–
>   - **äºŒä»·æ‹å– (Second-price auction)** : è·èƒœè€…æ”¯ä»˜ç¬¬äºŒé«˜çš„å‡ºä»·

2. **ä¸¥æ ¼å ä¼˜ (strictly dominated)**
   - ç­–ç•¥ 1 ä¸¥æ ¼å ä¼˜äºç­–ç•¥ 2 $\Leftrightarrow$ å¯¹äºä»»æ„å¯¹æ‰‹çš„ç­–ç•¥, é€‰ 1 çš„æ”¶ç›Šéƒ½**ä¸¥æ ¼å¤§äº** 2 
     - ç†æ€§äººä¸ä¼šé€‰æ‹©è¢«ä¸¥æ ¼å ä¼˜çš„ç­–ç•¥
   - **ä¸¥æ ¼å ä¼˜ç­–ç•¥ (Strictly dominant strategy)** : å…¶ä»–ç­–ç•¥éƒ½è¢«å®ƒå ä¼˜
   - **ä¸¥æ ¼å ä¼˜ç­–ç•¥å‡è¡¡ (Strictly dominant strategy equilibrium)**
     - ä¸¥æ ¼å ä¼˜ç­–ç•¥å‡è¡¡å­˜åœ¨åˆ™å”¯ä¸€
> å‡è¡¡åªæŒ‡å‡è¡¡æƒ…å†µä¸‹çš„ç­–ç•¥ç»„åˆ, è€Œéå‡è¡¡æƒ…å†µä¸‹çš„å›æŠ¥

3. **å¸•ç´¯æ‰˜å ä¼˜ (Pareto dominates)** : ç­–ç•¥ç»„åˆ $s$ å›æŠ¥ä¸ä½äº $s'$, ä¸”å­˜åœ¨è‡³å°‘ä¸€ä¸ªç©å®¶å›æŠ¥ä¸¥æ ¼æ›´é«˜
   - **å¸•ç´¯æ‰˜æœ‰æ•ˆ (Pareto optimal/Pareto efficient)** : ç­–ç•¥ç»„åˆä¸è¢«å…¶ä»–ç­–ç•¥å¸•ç´¯æ‰˜æ›´ä¼˜

> å›šå¾’å›°å¢ƒä¸­çš„ä¸¥æ ¼å ä¼˜å‡è¡¡å­˜åœ¨å¸•ç´¯æ‰˜æ”¹è¿›, æ˜¯å¦ä¸**ç¦åˆ©ç»æµå­¦ç¬¬ä¸€å®šç†**çŸ›ç›¾ï¼Ÿ
>    - æœ‰å‰æ: 
>      - å®Œå…¨ç«äº‰å¸‚åœº
>      - ä¸å­˜åœ¨å¤–éƒ¨æ€§ (externality): æ¶ˆè´¹è€…åªå…³å¿ƒè‡ªå·±çš„æ¶ˆè´¹, ç”Ÿäº§è€…åªå…³å¿ƒè‡ªå·±çš„ç”Ÿäº§, è€Œä¸ä¼šå—åˆ°ä»–äººæˆ–è€…å¤–éƒ¨ç¯å¢ƒçš„å½±å“
>   - å¸‚åœºç«äº‰èƒ½å¤Ÿé€šè¿‡ä»·æ ¼æœºåˆ¶æœ‰æ•ˆè°ƒèŠ‚ç»æµæ´»åŠ¨, è¾¾åˆ°å¸•ç´¯æ‰˜æœ€ä¼˜çš„èµ„æºé…ç½®

4.  **IESDS (iterated elimination of strictly dominated strategies)**
    - æ²¡æœ‰ä¸¥æ ¼å ä¼˜ç­–ç•¥æ—¶ä¹Ÿä¼šæœ‰å”¯ä¸€çš„ç»“æœ. 
      - å‚ä¸è€…çš„ç†æ€§æ˜¯ common knowledge æ—¶, IESDS æˆç«‹
    - **Iterated-elimination equilibrium** : åˆ å®Œåç­–ç•¥é›†çš„ç­–ç•¥ç»„åˆ
    - æœ‰é™åšå¼ˆä¸­åˆ é™¤æ¬¡åºå’Œæœ€ç»ˆç»“æœæ— å…³ç³»
    - strictly dominant strategy equilibrium å”¯ä¸€åœ°åœ¨ IESDS ä¸­å­˜æ´»

> - ç”¨ IESDS æ¥ç®—è¿ç»­çš„ Cournot Duopoly : ç±»ä¼¼é—­åŒºé—´å¥—å®šç†ä¼šæ”¶æ•›åˆ°çº³ä»€å‡è¡¡
> - IESDS æ— æ³•è§£å†³ n ä¸ª Cournot çš„é—®é¢˜ : åˆ äº†ä¸€è½®å°±åˆ ä¸ä¸‹å»äº†. 

5.  **æœ€ä¼˜ååº” (Best response)** : æœ€æ ¸å¿ƒçš„æ¦‚å¿µ, ä¸‹ç®€ç§°BR
    - æœ€ä¼˜ååº” $\Leftrightarrow$ ä¸è¢«ä¸¥æ ¼å ä¼˜
    - ä¸¥æ ¼å ä¼˜ç­–ç•¥æ˜¯ä»»ä½•ç­–ç•¥æ¥è¯´çš„å”¯ä¸€æœ€ä¼˜ååº”
    - **æœ€ä¼˜ååº”å¯¹åº” (Best response correspondence)** : æœ€ä¼˜ååº”çš„é›†åˆ

6.  **çº³ä»€å‡è¡¡ (Nash Equilibrium)** : ä¸‹ç®€ç§°NE
    - ç­–ç•¥ç»„åˆé‡Œé¢çš„æ¯ä¸ªç­–ç•¥éƒ½æ˜¯å¯¹æ‰‹ç­–ç•¥çš„æœ€ä¼˜ååº”
    - **å¯è·åˆ©çš„åç¦» (Profitable deviation)**: ç»™å®šç­–ç•¥ç»„åˆ, $i$ çš„å¦ä¸€ä¸ªç­–ç•¥ä½¿å…¶å›æŠ¥æ›´å¤§
      - NE $\Leftrightarrow$ æ— å¯è·åˆ©çš„åç¦» $\Leftrightarrow$ **äº’ä¸ºæœ€ä¼˜ååº” (mutual BR)**
    - **ä¸€è‡´æ€§** : ç©å®¶å¯¹å¯¹æ‰‹çš„çœ‹æ³•æ˜¯æ­£ç¡®çš„ (å³å‡è¡¡çŠ¶æ€ä¸‹çŸ¥é“å¯¹æ–¹çš„ç­–ç•¥)
    - ä¸¥æ ¼å ä¼˜ç­–ç•¥å‡è¡¡ä¸€å®šæ˜¯å”¯ä¸€çš„ NE
    - NE ä¼šåœ¨ IESDS ä¸­å­˜æ´» 


7.  **æ··åˆç­–ç•¥** : $\Delta S_i$ ($S_i$ ä¸Šé¢çš„æ‰€æœ‰æ¦‚ç‡åˆ†å¸ƒ) çš„å…ƒç´ 
    - **æ”¯æ’‘é›†** : $\text{supp } \sigma_i = \{s_i | \sigma_i(s_i) > 0\}$
    - æ··åˆç­–ç•¥ $\sigma_{i}$ æ˜¯ $\sigma_{-i}$ çš„BR $\Leftrightarrow$ ä¸å­˜åœ¨å¯è·åˆ©çš„çº¯ç­–ç•¥åç¦» $\Leftrightarrow$ æ”¯æ’‘é›†ä¸­**æ¯ä¸€ä¸ª**çº¯ç­–ç•¥éƒ½æ˜¯ $\sigma_{-i}$ çš„ BR
      - æ”¯æ’‘é›†æ— å·®å¼‚ 
      - ä»è€Œå¯ä»¥å®šä¹‰æ··åˆç­–ç•¥çš„ NE : mutual BR
    - æœ‰é™æ­£åˆ™åšå¼ˆä¸€å®šæœ‰ NE
    - **æ··åˆç­–ç•¥å ä¼˜** ï¼šæ··åˆç­–ç•¥å¯¹çº¯ç­–ç•¥å ä¼˜ 
      - ç›¸åº”æœ‰ IESDS 
      - original game çš„ NE $\Leftrightarrow$  IESDS åçš„ reduced game çš„ NE

## Handout 3

1. **æ‰©å±•å½¢å¼åšå¼ˆ (extensive form game)** : åºè´¯åšå¼ˆ (sequential game)
   - åšå¼ˆğŸŒ²,èŠ‚ç‚¹(nodes), ç©å®¶åˆ†é…(player assignment), å¯ç”¨è¡ŒåŠ¨(available action). 
   - **ä¿¡æ¯é›†** : èŠ‚ç‚¹é›†çš„ä¸€ç§åˆ’åˆ† 
     - ç©å®¶ä¸æ¸…æ¥šå¤„äºä¿¡æ¯é›†ä¸­çš„å“ªä¸ªèŠ‚ç‚¹
     - å¯ç”¨è¡ŒåŠ¨ç›¸åŒ
   - **å®Œç¾è®°å¿† (perfect recall)** : ç©å®¶è®°ä½ä»–ä»¬ä»¥å‰æ‰€é€‰æ‹©çš„è¡ŒåŠ¨. 
   - **å®Œç¾ä¿¡æ¯åšå¼ˆ (game of perfect information)** : æ¯ä¸ªä¿¡æ¯é›†éƒ½æ˜¯**å•ç‚¹(singleton)**
     - å®Œç¾ä¿¡æ¯åšå¼ˆå‚ä¸è€…æ‹¥æœ‰å®Œç¾å›å¿†


2. **æ‰©å±•å½¢å¼åšå¼ˆçš„ç­–ç•¥**: ä¸è®ºé€‰æ‹©è·¯å¾„å¦‚ä½•, ä¸ºæ¯ä¸ªä¿¡æ¯é›†åŒ¹é…è¡ŒåŠ¨. 
   - çº¯ç­–ç•¥ : ä»ä¿¡æ¯é›†åˆ°è¡ŒåŠ¨é›†çš„æ˜ å°„
     - æ¯ä¸ªç­–ç•¥ç»„åˆéƒ½ä¼šåˆ°è¾¾å”¯ä¸€çš„ç»ˆç‚¹, ç§°ä¸ºç»“æœ
   - æ··åˆç­–ç•¥ : çº¯ç­–ç•¥çš„åˆ†å¸ƒ
   - **è¡Œä¸ºç­–ç•¥**: ä¸ºæ¯ä¸ªä¿¡æ¯é›†æä¾›ä¸€ä¸ªè¡ŒåŠ¨é›†å…ƒç´ çš„åˆ†å¸ƒ
> æ··åˆç­–ç•¥ç»´åº¦ä¸ä½äºè¡Œä¸ºç­–ç•¥ : å‰è€…è•´å«äº†è·¯å¾„ç»è¿‡åŒä¸€ä¿¡æ¯é›†ä¸Šä¸åŒèŠ‚ç‚¹çš„æ¦‚ç‡åˆ†å¸ƒ. è‡ªç„¶å®Œç¾ä¿¡æ¯åšå¼ˆæ—¶è¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„ç»´åº¦ä¸º0.
   - åœ¨Perfect Recallæ¡ä»¶ä¸‹, å¯¹äºæ¯ä¸€ä¸ªmixed strategy, å­˜åœ¨ä¸€ä¸ªbehavioral strategyå’Œå‰è€…ç­‰ä»·, åä¹‹äº¦ç„¶.

3. **æ‰©å±•å½¢å¼åšå¼ˆçš„NE** : å³å†™æˆæ­£åˆ™è¡¨è¾¾çš„NE. 
   - å¦‚æœ $\sigma$ å¯ä»¥æ­£æ¦‚ç‡åˆ°è¾¾ä¸€ä¸ªä¿¡æ¯é›†, åˆ™è¯¥ä¿¡æ¯é›†åœ¨å‡è¡¡è·¯å¾„ä¸Š.
> **ä¸å¯ç½®ä¿¡çš„å¨èƒ**ä¼šå‡ºç°åœ¨å‡è¡¡è·¯å¾„å¤–
4. **é€†å‘å½’çº³æ³• (backward inducion)** : ä¸‹ç®€ç§°BI, å…¶è§£ä¸ºBI solution.
   - NEåªè¦æ±‚åœ¨å‡è¡¡è·¯å¾„ä¸Šæ¯ä¸ªäººéƒ½æœ€ä¼˜åŒ–, è€ŒBIåˆ™è¦æ±‚ä»»ä½•è·¯å¾„ä¸Šéƒ½è¦åšæœ€ä¼˜é€‰æ‹©
   - **åºè´¯ç†æ€§ (sequentially rational)**: åœ¨ä»»ä½•ä¸€ä¸ªä¿¡æ¯é›†ä¸Š, å½“å‰ç­–ç•¥éƒ½æ˜¯å¯¹æ‰‹ç­–ç•¥çš„BR. 
   - BIä¸è€ƒè™‘æœªæ¥èƒ½å¦æ”¹(ä¹Ÿå³ç»™å®šåç»­ç»“æœ), ä¸”ä¸å…³æ³¨å½“å‰ä¼šä¸ä¼šåˆ°è¾¾. 
   - ä¸€äº›å®šç†
     - å­˜åœ¨æ€§æ¡ä»¶ : ä»»æ„æœ‰é™å®Œç¾ä¿¡æ¯åšå¼ˆå­˜åœ¨BI solution. 
     - å”¯ä¸€æ€§æ¡ä»¶ : è‹¥æ²¡æœ‰äººè®¤ä¸ºä¸¤ä¸ªç»ˆç‚¹**æ— å·®å¼‚**, åˆ™æœ‰é™å®Œç¾ä¿¡æ¯åšå¼ˆBI solutionå”¯ä¸€. 
     - çº¯ç­–ç•¥æƒ…å†µä¸‹, BI solutionä¸€å®šæ˜¯NE.

5.  **æ‹“å±•å½¢å¼åšå¼ˆçš„å­åšå¼ˆ (subgame)** 
    - æ ¹æ‰€å±ä¿¡æ¯é›†æ˜¯å•ç‚¹é›†, æ ¹ç»§æ‰¿è€…çš„æ‰€å±ä¿¡æ¯é›†ä¸­çš„ç‚¹ä¹Ÿæ˜¯æ ¹ç»§æ‰¿è€…, åˆ™è¯¥æ ¹è¯±å¯¼å­åšå¼ˆ. 
    - **å­åšå¼ˆå®Œç¾å‡è¡¡ (SPE)** : è¡Œä¸ºç­–ç•¥ç»„åœ¨æ‰€æœ‰çš„å­åšå¼ˆä¸­éƒ½æ˜¯NE.
      - SPEè¦æ±‚æ‰€æœ‰è·¯å¾„ä¸Šçš„ç­–ç•¥ç»„åˆéƒ½æ˜¯mutual BR, æ— è®ºæ˜¯å¦åœ¨å‡è¡¡è·¯å¾„ä¸Š. 
    - æœ‰é™å®Œç¾ä¿¡æ¯åšå¼ˆä¸­, **SPE $\Leftrightarrow$ æ²¡æœ‰å¯è·åˆ©çš„ä¸€æ¬¡åç¦» $\Leftrightarrow$ BI solution**
> "SPE $\Leftrightarrow$ æ²¡æœ‰å¯è·åˆ©çš„ä¸€æ¬¡åç¦»" $\Rightarrow$ "SPE $\Leftrightarrow$ BI solution" $\Rightarrow$ "çº¯ç­–ç•¥BI solution = NE"
      
## Topic 1: é‡å¤åšå¼ˆ

1. **é‡å¤åšå¼ˆ (repeated game)** 
   - **é˜¶æ®µåšå¼ˆ (stage game)** : æŒ‡é‡å¤çš„ $n$ ä¸ªperiodä¸­çš„ä¸€ä¸ª 
     - é˜¶æ®µåšå¼ˆçš„å…¨éƒ¨ç­–ç•¥ç»„åˆ $A^n = A_1 \times ... \times A_n$. 
     - ç¬¬ $t$ æœŸçš„æ‰€æœ‰å¯èƒ½å†å² $H_t = A^t$ (set of all possible histories up to period $t$), æ˜¯tç»´å‘é‡çš„é›†åˆ, æ¯ä¸ªå…ƒç´ éƒ½æ˜¯æ‰€æœ‰äººçš„ç­–ç•¥ç»„åˆçš„æŸä¸ªå®ç°(åŠ¨ä½œç»„åˆ). 
     - é˜¶æ®µåšå¼ˆçº³ä»€å‡è¡¡ (stage NE): ä¾äºå½“å‰è½®æ”¶ç›Šçš„ NE
   - **æ€»å›æŠ¥ (total payoff)**: æ€»å’Œé˜¶æ®µåšå¼ˆæ”¶ç›Šè´´ç°ä¹‹å’Œ. å…¶ä¸­ $\delta \in (0,1]$ æ˜¯è´´ç°ç‡ 
$$v_i\equiv \sum_{t=1}^n\delta^{t-1}v_i^t$$
2. **é‡å¤åšå¼ˆçš„ç­–ç•¥**
$$s_i : \bigcup_{t=0}^{T-1}H_t\rightarrow A_i, \quad s_i=(s_i^1,s_i^2,\cdots,s_i^T),\quad s_i^t : H_{t-1}\to A_i.$$
3. **æœ‰é™æœŸé‡å¤åšå¼ˆ**
   - å¯¹äºåœ¨æ¯ä¸ªå†å²ä¸‹ç©å‡ºåŠ¨ä½œç»„åˆ $a^*=(a_1^*,\cdots,a_n^*)$ çš„ç­–ç•¥ $s$, å¦‚æœ $a^*$ æ˜¯stage NEåˆ™ $s$ æ˜¯SPE, å¦‚æœ $a^*$ å”¯ä¸€åˆ™ SPE å”¯ä¸€
   - æœ€åä¸€æœŸä¸€å®šç©çš„æ˜¯ stage NE. 
4. **æ— é™æœŸé‡å¤åšå¼ˆ**
   - æ— ç©·åšå¼ˆä¸‹, ä¸€ç›´ç©åŒä¸€ä¸ªstage NE, å¾—åˆ°çš„æ˜¯SPE. 
   - è‹¥ stage NE æœ‰å¸•ç´¯æ‰˜ä¸¥æ ¼æ”¹è¿› $a$, é‚£ä¹ˆä¸€å®šå­˜åœ¨è¶³å¤Ÿå¤§çš„è´´ç°å€¼, ä½¿å¾—å­˜åœ¨ä¸€ä¸ªSPE, å‡è¡¡ç»“æœä¸Šåœ¨è·¯å¾„ä¸Šä¸€ç›´åœ¨ç©a. 

## Handout 4

1. **è´å¶æ–¯åšå¼ˆ/é™æ€éå®Œå…¨ä¿¡æ¯åšå¼ˆ (Bayesian game)**
   - **definition** : ä¸€ä¸ªäº”å…ƒç»„ : $(N=[n],\{A_i\}_n,\{\Theta_i\}_n,\{v_i\}_n,\mathbb P)$
     - $A_i$ : ç©å®¶ $i$ çš„åŠ¨ä½œç©ºé—´
     - $\Theta_i$ : ç©å®¶ $i$ çš„ç±»å‹ç©ºé—´
     - $v_i : A\times \Theta \to \mathbb R$ : ç©å®¶ $i$ çš„æ”¯ä»˜å‡½æ•°, ä¾‹å¦‚ $v_i(a;\theta)$
     - $\mathbb P$ : $\Theta$ ä¸Šçš„åˆ†å¸ƒ, ç©å®¶ä»¬å…·å¤‡çš„ä¸€ä¸ª**å…±åŒå…ˆéªŒ(common prior)**.
   - **å…³äºç±»å‹çš„åéªŒæ¦‚ç‡(posterior belief about his opponentsâ€™ types)**  : $\phi(\cdot|\theta_i)$. å…¶ä¸­ $\phi(\theta_{-i}|\theta_i)=\mathbb P(\theta_i,\theta_{-i})/\mathbb P(\theta_i)$
   - çº¯ç­–ç•¥ $s_i : \Theta_i\to A_i$, æ··åˆç­–ç•¥ $\sigma_i : \Theta_i\to\Delta(A_i)$
   - çº¯ç­–ç•¥è´å¶æ–¯NE : $s^*=(s_1^*,s_2^*,\dots,s_n^*) \;\text{s.t.}\;\forall i,\forall \theta_{ij}\in \Theta_i,\forall a_i\in A_i$
$$\sum_{\theta_{-i}\in \Theta_{-i}}\phi_i(\theta_{-i}|\theta_{ij})v_i(s_i^*(\theta_{ij}),s^*_{-i}(\theta_{-i});\theta_i,\theta_{-i})\\\leq \sum_{\theta_{-i}\in \Theta_{-i}}\phi_i(\theta_{-i}|\theta_{ij})v_i(a_i,s^*_{-i}(\theta_{-i});\theta_i,\theta_{-i})$$ 
> $P(B|A) = P(AB)/P(A)$

 
## å¾€å¹´é¢˜å‹æ•´ç†
> ä¸åŒå½¢å¼è¯­è¨€çš„å¤æ‚åº¦ä¸åŒ, è€Œäººçš„æ¼”ç®—èƒ½åŠ›æ˜¯å®šå€¼. å› æ­¤å½¢å¼è¯­è¨€æˆ–è€…æ¨¡å‹è¶Šå¤æ‚, é—®é¢˜æœ¬èº«è¶Šç®€å•.
> ä¸åŒé—®é¢˜çš„è§„æ¨¡ä¸åŒ, è€Œäººçš„æ¼”ç®—èƒ½åŠ›æ˜¯å®šå€¼. å› æ­¤é—®é¢˜è§„æ¨¡è¶Šå¤§, è¶Šå®¹æ˜“å­˜åœ¨å·§å¦™çš„trick.
### 1. åŒå˜é‡çŸ©é˜µé¢˜å‹
å³ç­–ç•¥æœ‰é™, ä»å¤šä¸ªé€‰æ‹©ä¸­æ··åˆorçº¯ç­–ç•¥, å¾€å¾€èƒ½çœ‹åˆ°åŒå˜é‡çŸ©é˜µ
> (1) ğŸ”¥ Does player 1 have a strictly dominated strategy? If yes, show which strategy strictly dominates which strategy. If no, explain why.
- é¦–å…ˆéœ€è¦æ³¨æ„ dominance æ˜¯å¦è€ƒè™‘æ··åˆç­–ç•¥
- ç›´æ¥çœ‹çŸ©é˜µæ•°å€¼, å¦‚æœæŸç­–ç•¥åœ¨å¯¹æ‰‹çš„æŸä¸ªçº¯ç­–ç•¥ä¸‹æ˜¯æœ€ä¼˜ååº”, åˆ™å¿…ä¸å¯èƒ½è¢«å ä¼˜, åˆ©ç”¨è¿™ä¸ªåšæ’é™¤æ³•
  - å¦‚æœå­˜åœ¨æŸä¸ªç­–ç•¥è¢«å ä¼˜, ç›´æ¥å†™è°è¢«è°å 
  - å¦‚æœä¸å­˜åœ¨, ç†ç”±å¦‚ä¸‹: Player 1 has no strictly dominated strategy. This is because each (pure) strategy is a best response to some of player 1â€™s strategy.
> (2) ğŸ”¥ What strategies survive the process of iterated elimination of strictly dominated strategies? In each step of your deletion, show which strategy is strictly dominated by which strategy.
- æŒ‰éƒ¨å°±ç­IESDSå³å¯, æ³¨æ„èƒ½ä¸èƒ½æ··åˆä»¥åŠä¸è¦æŠŠä¸¥æ ¼å ä¼˜å’Œå¸•ç´¯æ‰˜æ›´ä¼˜æ··æ·†, æ²¡æœ‰é™·é˜±
> (3) ğŸ”¥ğŸ”¥ğŸ”¥ Find all Nash equilibria (pure and mixed) of this game.
- é¦–å…ˆå‚è€ƒ1(2)å¾—åˆ° reduced form
- ä¸€èˆ¬ä¸¤ç§æ€è·¯, å‰è€…å¯èƒ½ç¨ç¹ç, åè€…éœ€è¦æ³¨æ„åŠ›, å®æˆ˜å¤§å¤šæ˜¯åè€…
  - ä¸€ç§æ˜¯**ä»ä¸‹è‡³ä¸Š**, æšä¸¾å¹¶ç»™å‡ºæ”¯æ’‘é›†ä¸Šnashå‡è¡¡çš„å…¨éƒ¨å¿…è¦æ¡ä»¶
    - çº¯ç­–ç•¥æœ‰é™, ç›´æ¥æ‰¾
    - æ··åˆç­–ç•¥ç”¨å¥½NEçš„å……è¦æ¡ä»¶ : æ··åˆçš„ä¸€æ–¹æ”¯æ’‘é›†æ— å·®å¼‚ä¸”å‡æœ€ä¼˜
  - å¦ä¸€ç§æ˜¯**ä»ä¸Šåˆ°ä¸‹**, å¯¹ä¸€äº›æ¡ä»¶ç»™å‡ºç›¸åº”çš„çº¦æŸæ¥ç¼©å°ç­”æ¡ˆèŒƒå›´
    - å¸¸è§çš„æ¡ä»¶åŒ…æ‹¬:
      - $\sigma_1(X)>0$ ç”¨äºæ’é™¤è¢«å¸•ç´¯æ‰˜æ›´ä¼˜çš„ X
      - $\sigma_1(X)=1$ ç”¨äºè®¨è®ºä¸€æ–¹çº¯ç­–ç•¥å¦ä¸€æ–¹æ··åˆç­–ç•¥çš„æƒ…å½¢
- ä¸å¿…å›¿äºå…¬å¼åšé¢˜æˆ–è€…NEå……è¦æ¡ä»¶, æŠŠè‡ªå·±ä»£å…¥ç©å®¶å»è€ƒè™‘å¯è·åˆ©åç¦»å¯ä»¥æé«˜æ³¨æ„åŠ›
- è¡¥å……1: åŒäººåšå¼ˆä¸å­˜åœ¨ä¸€ä¸ªä½¿å¾—nashå‡è¡¡åˆ†å¸ƒåœ¨å¯¹è§’çº¿ä¸Šçš„ä¸€èˆ¬æ¡ä»¶, å› æ­¤ä¸èƒ½å‡è®¾çº³ä»€å‡è¡¡ä¸‹ä¸¤äººæˆ–è€…å¤šäººçš„ç­–ç•¥åˆ†å¸ƒç›¸åŒ
  - ä¸€äº›è§„æ¨¡è¾ƒå¤§çš„é—®é¢˜, å¯èƒ½å‡ºç°å‚ä¸è€…åœ°ä½å¯¹ç§°çš„æƒ…å½¢ä»¥é™ä½è®¡ç®—é‡. è¡¥å……1å‘Šè¯‰æˆ‘ä»¬, å¯¹ç§°æ€§åªèƒ½åŒç†å¯¹å‚ä¸è€…çš„è®¨è®º, è€Œä¸ä¸ºè®¨è®ºæä¾›é¢å¤–çš„æ€§è´¨
- è¡¥å……2: æœ‰é™åšå¼ˆä¸‹nashå‡è¡¡å½“ç„¶å¾€å¾€æ˜¯æœ‰ç•Œé—­çš„, ä½†è¿™ä¸ä»£è¡¨å¯ä»¥ç”¨æ··åˆç­–ç•¥è®¨è®ºçº¯ç­–ç•¥, å› ä¸ºå•ç‚¹å’Œçº¿æ®µä¹Ÿæœ‰ç•Œé—­
  - ä»»ä½•æƒ…å†µä¸‹éƒ½å°†çº¯ç­–ç•¥å’Œæ··åˆç­–ç•¥åˆ†ç±»è®¨è®º
> (4) ğŸ”¥ğŸ”¥ Find all Pareto efficient strategy profiles.
- å®¹æ˜“è¢«å¿½ç•¥çš„ä¸€ç§é¢˜å‹, å¹¶ä¸”éœ€è¦æ³¨æ„åŠ›
- å½“ä½ æšä¸¾äº†è¢«å¸•ç´¯æ‰˜å ä¼˜çš„æ‰€æœ‰å…¶ä»–å‡è¡¡å, å°±å¯ä»¥å†™æ˜¾ç„¶äº†
### 2. å‡ºä»·ç±»é¢˜å‹
è¿™æ„å‘³ç€ç­–ç•¥é›†æ˜¯è¿ç»­åŒºé—´, åŒ…æ‹¬æ‹å–, å¤è¯ºæ¨¡å‹ç­‰
> (1) ğŸ”¥ Show that XXX is a Nash equilibrium.
- èƒ½é—®å‡ºè¿™ä¸ªé—®é¢˜brå¤§æ¦‚ç‡æ¯”è¾ƒéš¾å†™, åˆ«æ±‚äº¤ç‚¹äº†.
- å†™å‡ºæ•ˆç”¨å‡½æ•°, éªŒè¯æ¯ä¸ªç©å®¶æ— å¯è·åˆ©åç¦»å³å¯
> (2) ğŸ”¥ğŸ”¥ Find a Nash equilibrium
- æ£æ‘©NEçš„æ¡ä»¶ç»™å‡ºæ„é€ , å†ç±»ä¼¼ä¸Šé¢˜, éœ€è¦æ³¨æ„åŠ›
- ä¸€èˆ¬å¾€å¯¹ç§°ç­–ç•¥æˆ–è€…å•æ–¹é¢ç¢¾å‹è·èƒœçš„ç­–ç•¥æƒ³
### 3. åšå¼ˆæ ‘é¢˜å‹
è¿™é‡Œç‰¹åˆ¶å®Œå…¨ä¿¡æ¯çš„åºè´¯åšå¼ˆ
> (1) ğŸ”¥ Find a mixed strategy Nash equilibrium.
- å‚è€ƒ 2(2), ä¸€èˆ¬åªç”¨è€ƒè™‘å¯¹ç§°çš„ç­–ç•¥, è®¾å‡ºæ‰€æœ‰å…¶ä»–äººçš„åˆ†å¸ƒä¸º $p$, å†è§£æœ€åä¸€ä¸ªäººçš„æ··åˆå……è¦æ¡ä»¶ (æ”¯æ’‘é›†æ— å·®å¼‚ä¸”å‡æœ€ä¼˜), è§£å‡º $p$ åå¤§å®¶éƒ½ç”¨è¿™ä¸ª $p$, å°±çœå»äº†éªŒè¯
> (2) ğŸ”¥ Draw the game tree for this game, including the payoffs. 
- ç›´æ¥ç”»å³å¯, æ³¨æ„å®¡é¢˜, ä¿¡æ¯é›†å®¹æ˜“æ¼
> (3) ğŸ”¥ğŸ”¥ğŸ”¥ Find all pure strategy Nash equilibria in which the road is built.
- å¤æ‚çš„é¢˜, å…ˆåˆ—ç­–ç•¥é›†, å³æ¯ä¸ªäººå¯¹å±äºå…¶çš„æ¯ä¸ªä¿¡æ¯é›†ç»™å‡ºç­–ç•¥.
> (4) ğŸ”¥ Find a backward induction solution.
- ç›´æ¥é€†å‘å½’çº³å³å¯, ç»™å‡ºçš„solutionåº”å½“å½¢å¦‚ $(\sigma_1,\sigma_2,\cdots,\sigma_n)$
> (5) ğŸ”¥ğŸ”¥ Find a Nash equilibrium that is not a backward induction solution.
- ä¸“é—¨æ„é€ , ä½¿å¾—åœ¨éå‡è¡¡è·¯å¾„ä¸Šä¸æ˜¯nashå‡è¡¡.
